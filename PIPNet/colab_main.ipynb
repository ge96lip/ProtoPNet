{"cells":[{"cell_type":"code","execution_count":2,"id":"QMsgm9mM3ifC","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2057,"status":"ok","timestamp":1721294531501,"user":{"displayName":"hanad abdullahi","userId":"11074746584642627268"},"user_tz":-120},"id":"QMsgm9mM3ifC","outputId":"d90ec2f7-b7e4-4978-d0e9-ca887781e918"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import os\n","import shutil\n","import pandas as pd\n","import sys\n","from google.colab import drive\n","# Mount the drive\n","drive.mount('/content/drive')\n","\n","# Change the directory to the specific folder\n","os.chdir('/content/drive/My Drive/PIPNet')\n","#OKEJ, SKA DU KÖRA NY DATA\n","#sTEG 1: Ändra PATH\n","#STEG 2: ÄNDRA NAMN PÅ RUN NÄR DU ÄR KLAR\n","#steg 3: Ändra normalisering\n"]},{"cell_type":"code","execution_count":null,"id":"5a4ec387","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3586,"status":"ok","timestamp":1720131093733,"user":{"displayName":"hanad abdullahi","userId":"11074746584642627268"},"user_tz":-120},"id":"5a4ec387","outputId":"6985f3a4-5da1-448a-a8fb-6fdbc010cd9d"},"outputs":[{"name":"stdout","output_type":"stream","text":["hej du har kommit in i get_Args\n","NU ÄR DEN I PRINT STADIET KOLLA HIT AHAND\n"]}],"source":["from pipnet.pipnet import PIPNet, get_network\n","from util.log import Log\n","from visualize_test import vis_pred2, vis_pred_experiments2\n","from run_test_code import test_pipnet\n","import torch.nn as nn\n","from util.args import get_args, save_args, get_optimizer_nn\n","from util.data import get_dataloaders\n","from data_2 import get_dataloaders2\n","from util.func import init_weights_xavier\n","from pipnet.train import train_pipnet\n","from pipnet.test import eval_pipnet, get_thresholds, eval_ood\n","from util.eval_cub_csv import eval_prototypes_cub_parts_csv, get_topk_cub, get_proto_patches_cub\n","import torch\n","from util.vis_pipnet import visualize, visualize_topk\n","from util.visualize_prediction import vis_pred, vis_pred_experiments\n","import sys, os\n","import random\n","import numpy as np\n","from shutil import copy\n","import matplotlib.pyplot as plt\n","from copy import deepcopy"]},{"cell_type":"code","execution_count":null,"id":"HD1AENsJtJW_","metadata":{"id":"HD1AENsJtJW_"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"V7ejaCZ4s7jI","metadata":{"id":"V7ejaCZ4s7jI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"09d18f9a","metadata":{"id":"09d18f9a"},"outputs":[],"source":["def run_pipnet(args):\n","    print(\"den är inne i en funktion\")\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","\n","    args = args or get_args()\n","    assert args.batch_size > 1\n","\n","    # Create a logger\n","    log = Log(args.log_dir)\n","    print(\"Log dir: \", args.log_dir, flush=True)\n","    # Log the run arguments\n","    save_args(args, log.metadata_dir)\n","\n","    gpu_list = args.gpu_ids.split(',')\n","    device_ids = []\n","    if args.gpu_ids!='':\n","        for m in range(len(gpu_list)):\n","            device_ids.append(int(gpu_list[m]))\n","\n","    global device\n","    if not args.disable_cuda and torch.cuda.is_available():\n","        if len(device_ids)==1:\n","            device = torch.device('cuda:{}'.format(args.gpu_ids))\n","        elif len(device_ids)==0:\n","            device = torch.device('cuda')\n","            print(\"CUDA device set without id specification\", flush=True)\n","            device_ids.append(torch.cuda.current_device())\n","        else:\n","            print(\"This code should work with multiple GPU's but we didn't test that, so we recommend to use only 1 GPU.\", flush=True)\n","            device_str = ''\n","            for d in device_ids:\n","                device_str+=str(d)\n","                device_str+=\",\"\n","            device = torch.device('cuda:'+str(device_ids[0]))\n","    else:\n","        device = torch.device('cpu')\n","\n","    # Log which device was actually used\n","    print(\"Device used: \", device, \"with id\", device_ids, flush=True)\n","    #ALLT OVANFÖR ÄR CUDA, UNDER ÄR DATAHANTERING\n","    #----------------------------------------------------------------------------------------------------------------------------------\n","    # Obtain the dataset and dataloaders\n","    trainloader, trainloader_pretraining, trainloader_normal, trainloader_normal_augment,projectloader, testloader, test_projectloader, classes = get_dataloaders(args, device)\n","    trainloader2, trainloader_pretraining2, trainloader_normal2, trainloader_normal_augment2,projectloader2, testloader2, test_projectloader2, classes2 = get_dataloaders2(args, device)\n","    if len(classes)<=20:\n","        if args.validation_size == 0.:\n","            print(\"Classes: \", testloader.dataset.class_to_idx, flush=True)\n","        else:\n","            print(\"Classes: \", str(classes), flush=True)\n","\n","    # Create a convolutional network based on arguments and add 1x1 conv layer\n","    feature_net, add_on_layers, pool_layer, classification_layer, num_prototypes = get_network(len(classes), args)\n","\n","    # Create a PIP-Net\n","    net = PIPNet(num_classes=len(classes),\n","                    num_prototypes=num_prototypes,\n","                    feature_net = feature_net,\n","                    args = args,\n","                    add_on_layers = add_on_layers,\n","                    pool_layer = pool_layer,\n","                    classification_layer = classification_layer\n","                    )\n","    net = net.to(device=device)\n","    net = nn.DataParallel(net, device_ids = device_ids)\n","\n","    optimizer_net, optimizer_classifier, params_to_freeze, params_to_train, params_backbone = get_optimizer_nn(net, args)\n","\n","    # Initialize or load model\n","    with torch.no_grad():\n","        if args.state_dict_dir_net != '':\n","            epoch = 0\n","            checkpoint = torch.load(args.state_dict_dir_net,map_location=device)\n","            net.load_state_dict(checkpoint['model_state_dict'],strict=True)\n","            print(\"Pretrained network loaded\", flush=True)\n","            net.module._multiplier.requires_grad = False\n","            try:\n","                optimizer_net.load_state_dict(checkpoint['optimizer_net_state_dict'])\n","            except:\n","                pass\n","            if torch.mean(net.module._classification.weight).item() > 1.0 and torch.mean(net.module._classification.weight).item() < 3.0 and torch.count_nonzero(torch.relu(net.module._classification.weight-1e-5)).float().item() > 0.8*(num_prototypes*len(classes)): #assume that the linear classification layer is not yet trained (e.g. when loading a pretrained backbone only)\n","                print(\"We assume that the classification layer is not yet trained. We re-initialize it...\", flush=True)\n","                torch.nn.init.normal_(net.module._classification.weight, mean=1.0,std=0.1)\n","                torch.nn.init.constant_(net.module._multiplier, val=2.)\n","                print(\"Classification layer initialized with mean\", torch.mean(net.module._classification.weight).item(), flush=True)\n","                if args.bias:\n","                    torch.nn.init.constant_(net.module._classification.bias, val=0.)\n","            # else: #uncomment these lines if you want to load the optimizer too\n","            #     if 'optimizer_classifier_state_dict' in checkpoint.keys():\n","            #         optimizer_classifier.load_state_dict(checkpoint['optimizer_classifier_state_dict'])\n","\n","        else:\n","            net.module._add_on.apply(init_weights_xavier)\n","            torch.nn.init.normal_(net.module._classification.weight, mean=1.0,std=0.1)\n","            if args.bias:\n","                torch.nn.init.constant_(net.module._classification.bias, val=0.)\n","            torch.nn.init.constant_(net.module._multiplier, val=2.)\n","            net.module._multiplier.requires_grad = False\n","\n","            print(\"Classification layer initialized with mean\", torch.mean(net.module._classification.weight).item(), flush=True)\n","\n","    # Define classification loss function and scheduler\n","    criterion = nn.NLLLoss(reduction='mean').to(device)\n","    scheduler_net = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, T_max=len(trainloader_pretraining)*args.epochs_pretrain, eta_min=args.lr_block/100., last_epoch=-1)\n","\n","    # Forward one batch through the backbone to get the latent output size\n","    with torch.no_grad():\n","        xs1, _, _ = next(iter(trainloader))\n","        xs1 = xs1.to(device)\n","        proto_features, _, _ = net(xs1)\n","        wshape = proto_features.shape[-1]\n","        args.wshape = wshape #needed for calculating image patch size\n","        print(\"Output shape: \", proto_features.shape, flush=True)\n","\n","    if net.module._num_classes == 2:\n","        # Create a csv log for storing the test accuracy, F1-score, mean train accuracy and mean loss for each epoch\n","        log.create_log('log_epoch_overview', 'epoch', 'test_top1_acc', 'test_f1', 'almost_sim_nonzeros', 'local_size_all_classes','almost_nonzeros_pooled', 'num_nonzero_prototypes', 'mean_train_acc', 'mean_train_loss_during_epoch')\n","        print(\"Your dataset only has two classes. Is the number of samples per class similar? If the data is imbalanced, we recommend to use the --weighted_loss flag to account for the imbalance.\", flush=True)\n","    else:\n","        # Create a csv log for storing the test accuracy (top 1 and top 5), mean train accuracy and mean loss for each epoch\n","        log.create_log('log_epoch_overview', 'epoch', 'test_top1_acc', 'test_top5_acc', 'almost_sim_nonzeros', 'local_size_all_classes','almost_nonzeros_pooled', 'num_nonzero_prototypes', 'mean_train_acc', 'mean_train_loss_during_epoch')\n","\n","\n","    lrs_pretrain_net = []\n","    best_accuracy = 0.0\n","    # PRETRAINING PROTOTYPES PHASE\n","    for epoch in range(1, args.epochs_pretrain+1):\n","        for param in params_to_train:\n","            param.requires_grad = True\n","        for param in net.module._add_on.parameters():\n","            param.requires_grad = True\n","        for param in net.module._classification.parameters():\n","            param.requires_grad = False\n","        for param in params_to_freeze:\n","            param.requires_grad = True # can be set to False when you want to freeze more layers\n","        for param in params_backbone:\n","            param.requires_grad = False #can be set to True when you want to train whole backbone (e.g. if dataset is very different from ImageNet)\n","\n","        print(\"\\nPretrain Epoch\", epoch, \"with batch size\", trainloader_pretraining.batch_size, flush=True)\n","\n","        # Pretrain prototypes\n","        train_info = train_pipnet(net, trainloader_pretraining, optimizer_net, optimizer_classifier, scheduler_net, None, criterion, epoch, args.epochs_pretrain, device, pretrain=True, finetune=False)\n","        lrs_pretrain_net+=train_info['lrs_net']\n","        plt.clf()\n","        plt.plot(lrs_pretrain_net)\n","        plt.savefig(os.path.join(args.log_dir,'lr_pretrain_net.png'))\n","        log.log_values('log_epoch_overview', epoch, \"n.a.\", \"n.a.\", \"n.a.\", \"n.a.\", \"n.a.\", \"n.a.\", \"n.a.\", train_info['loss'])\n","\n","    if args.state_dict_dir_net == '':\n","        net.eval()\n","        torch.save({'model_state_dict': net.state_dict(), 'optimizer_net_state_dict': optimizer_net.state_dict()}, os.path.join(os.path.join(args.log_dir, 'checkpoints'), 'net_pretrained'))\n","        net.train()\n","    with torch.no_grad():\n","        if 'convnext' in args.net and args.epochs_pretrain > 0:\n","            topks = visualize_topk(net, projectloader, len(classes), device, 'visualised_pretrained_prototypes_topk', args)\n","\n","    # SECOND TRAINING PHASE\n","    # re-initialize optimizers and schedulers for second training phase\n","    optimizer_net, optimizer_classifier, params_to_freeze, params_to_train, params_backbone = get_optimizer_nn(net, args)\n","    scheduler_net = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer_net, T_max=len(trainloader)*args.epochs, eta_min=args.lr_net/100.)\n","    # scheduler for the classification layer is with restarts, such that the model can re-active zeroed-out prototypes. Hence an intuitive choice.\n","    if args.epochs<=30:\n","        scheduler_classifier = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_classifier, T_0=5, eta_min=0.001, T_mult=1, verbose=False)\n","    else:\n","        scheduler_classifier = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer_classifier, T_0=10, eta_min=0.001, T_mult=1, verbose=False)\n","    for param in net.module.parameters():\n","        param.requires_grad = False\n","    for param in net.module._classification.parameters():\n","        param.requires_grad = True\n","\n","    frozen = True\n","    lrs_net = []\n","    lrs_classifier = []\n","\n","    for epoch in range(1, args.epochs + 1):\n","        epochs_to_finetune = 3 #during finetuning, only train classification layer and freeze rest. usually done for a few epochs (at least 1, more depends on size of dataset)\n","        if epoch <= epochs_to_finetune and (args.epochs_pretrain > 0 or args.state_dict_dir_net != ''):\n","            for param in net.module._add_on.parameters():\n","                param.requires_grad = False\n","            for param in params_to_train:\n","                param.requires_grad = False\n","            for param in params_to_freeze:\n","                param.requires_grad = False\n","            for param in params_backbone:\n","                param.requires_grad = False\n","            finetune = True\n","\n","        else:\n","            finetune=False\n","            if frozen:\n","                # unfreeze backbone\n","                if epoch>(args.freeze_epochs):\n","                    for param in net.module._add_on.parameters():\n","                        param.requires_grad = True\n","                    for param in params_to_freeze:\n","                        param.requires_grad = True\n","                    for param in params_to_train:\n","                        param.requires_grad = True\n","                    for param in params_backbone:\n","                        param.requires_grad = True\n","                    frozen = False\n","                # freeze first layers of backbone, train rest\n","                else:\n","                    for param in params_to_freeze:\n","                        param.requires_grad = True #Can be set to False if you want to train fewer layers of backbone\n","                    for param in net.module._add_on.parameters():\n","                        param.requires_grad = True\n","                    for param in params_to_train:\n","                        param.requires_grad = True\n","                    for param in params_backbone:\n","                        param.requires_grad = False\n","\n","        print(\"\\n Epoch\", epoch, \"frozen:\", frozen, flush=True)\n","        if (epoch==args.epochs or epoch%30==0) and args.epochs>1:\n","            # SET SMALL WEIGHTS TO ZERO\n","            with torch.no_grad():\n","                torch.set_printoptions(profile=\"full\")\n","                net.module._classification.weight.copy_(torch.clamp(net.module._classification.weight.data - 0.001, min=0.))\n","                print(\"Classifier weights: \", net.module._classification.weight[net.module._classification.weight.nonzero(as_tuple=True)], (net.module._classification.weight[net.module._classification.weight.nonzero(as_tuple=True)]).shape, flush=True)\n","                if args.bias:\n","                    print(\"Classifier bias: \", net.module._classification.bias, flush=True)\n","                torch.set_printoptions(profile=\"default\")\n","\n","        train_info = train_pipnet(net, trainloader, optimizer_net, optimizer_classifier, scheduler_net, scheduler_classifier, criterion, epoch, args.epochs, device, pretrain=False, finetune=finetune)\n","        lrs_net+=train_info['lrs_net']\n","        lrs_classifier+=train_info['lrs_class']\n","        # Evaluate model\n","        eval_info = eval_pipnet(net, testloader, epoch, device, log)\n","        log.log_values('log_epoch_overview', epoch, eval_info['top1_accuracy'], eval_info['top5_accuracy'], eval_info['almost_sim_nonzeros'], eval_info['local_size_all_classes'], eval_info['almost_nonzeros'], eval_info['num non-zero prototypes'], train_info['train_accuracy'], train_info['loss'])\n","          # Save model if it has the best accuracy\n","        if eval_info['top1_accuracy'] > best_accuracy:\n","\n","            best_accuracy = eval_info['top1_accuracy']\n","            torch.save({\n","                  'model_state_dict': net.state_dict(),\n","                  'optimizer_net_state_dict': optimizer_net.state_dict(),\n","                  'optimizer_classifier_state_dict': optimizer_classifier.state_dict()\n","              }, os.path.join(args.log_dir, 'checkpoints', f\"best_model.pth\"))\n","            print(f\"CURRENT BEST MODEL AT EPOCH {epoch}\")\n","\n","\n","        with torch.no_grad():\n","            net.eval()\n","            torch.save({'model_state_dict': net.state_dict(), 'optimizer_net_state_dict': optimizer_net.state_dict(), 'optimizer_classifier_state_dict': optimizer_classifier.state_dict()}, os.path.join(os.path.join(args.log_dir, 'checkpoints'), 'net_trained'))\n","\n","            if epoch%30 == 0:\n","                net.eval()\n","                torch.save({'model_state_dict': net.state_dict(), 'optimizer_net_state_dict': optimizer_net.state_dict(), 'optimizer_classifier_state_dict': optimizer_classifier.state_dict()}, os.path.join(os.path.join(args.log_dir, 'checkpoints'), 'net_trained_%s'%str(epoch)))\n","\n","            # save learning rate in figure\n","            plt.clf()\n","            plt.plot(lrs_net)\n","            plt.savefig(os.path.join(args.log_dir,'lr_net.png'))\n","            plt.clf()\n","            plt.plot(lrs_classifier)\n","            plt.savefig(os.path.join(args.log_dir,'lr_class.png'))\n","\n","    net.eval()\n","    torch.save({'model_state_dict': net.state_dict(), 'optimizer_net_state_dict': optimizer_net.state_dict(), 'optimizer_classifier_state_dict': optimizer_classifier.state_dict()}, os.path.join(os.path.join(args.log_dir, 'checkpoints'), 'net_trained_last'))\n","    net2 = net\n","    topks = visualize_topk(net, projectloader, len(classes), device, 'visualised_prototypes_topk', args)\n","    # set weights of prototypes that are never really found in projection set to 0\n","    set_to_zero = []\n","    if topks:\n","        for prot in topks.keys():\n","            found = False\n","            for (i_id, score) in topks[prot]:\n","                if score > 0.001:\n","                    found = True\n","            if not found:\n","                torch.nn.init.zeros_(net.module._classification.weight[:,prot])\n","                set_to_zero.append(prot)\n","        print(\"Weights of prototypes\", set_to_zero, \"are set to zero because it is never detected with similarity>0.1 in the training set\", flush=True)\n","        eval_info = eval_pipnet(net, testloader, \"notused\"+str(args.epochs), device, log)\n","        log.log_values('log_epoch_overview', \"notused\"+str(args.epochs), eval_info['top1_accuracy'], eval_info['top5_accuracy'], eval_info['almost_sim_nonzeros'], eval_info['local_size_all_classes'], eval_info['almost_nonzeros'], eval_info['num non-zero prototypes'], \"n.a.\", \"n.a.\")\n","\n","    print(\"classifier weights: \", net.module._classification.weight, flush=True)\n","    print(\"Classifier weights nonzero: \", net.module._classification.weight[net.module._classification.weight.nonzero(as_tuple=True)], (net.module._classification.weight[net.module._classification.weight.nonzero(as_tuple=True)]).shape, flush=True)\n","    print(\"Classifier bias: \", net.module._classification.bias, flush=True)\n","    # Print weights and relevant prototypes per class\n","    for c in range(net.module._classification.weight.shape[0]):\n","        relevant_ps = []\n","        proto_weights = net.module._classification.weight[c,:]\n","        for p in range(net.module._classification.weight.shape[1]):\n","            if proto_weights[p]> 1e-3:\n","                relevant_ps.append((p, proto_weights[p].item()))\n","        if args.validation_size == 0.:\n","            print(\"Class\", c, \"(\", list(testloader.dataset.class_to_idx.keys())[list(testloader.dataset.class_to_idx.values()).index(c)],\"):\",\"has\", len(relevant_ps),\"relevant prototypes: \", relevant_ps, flush=True)\n","\n","    # Evaluate prototype purity\n","    if args.dataset == 'CUB-200-2011':\n","      print(\"Nu är den och utvärderar protyperna\")\n","      projectset_img0_path = projectloader.dataset.samples[0][0]\n","      project_path = os.path.split(os.path.split(projectset_img0_path)[0])[0].split(\"dataset\")[0]\n","      parts_loc_path = os.path.join(project_path, \"parts/part_locs.txt\")\n","      parts_name_path = os.path.join(project_path, \"parts/parts.txt\")\n","      imgs_id_path = os.path.join(project_path, \"images.txt\")\n","      cubthreshold = 0.5\n","\n","      net.eval()\n","      print(\"\\n\\nEvaluating cub prototypes for training set\", flush=True)\n","      csvfile_topk = get_topk_cub(net, projectloader, 10, 'train_'+str(epoch), device, args)\n","      eval_prototypes_cub_parts_csv(csvfile_topk, parts_loc_path, parts_name_path, imgs_id_path, 'train_topk_'+str(epoch), args, log)\n","\n","      csvfile_all = get_proto_patches_cub(net, projectloader, 'train_all_'+str(epoch), device, args, threshold=cubthreshold)\n","      eval_prototypes_cub_parts_csv(csvfile_all, parts_loc_path, parts_name_path, imgs_id_path, 'train_all_thres'+str(cubthreshold)+'_'+str(epoch), args, log)\n","\n","      print(\"\\n\\nEvaluating cub prototypes for test set\", flush=True)\n","      csvfile_topk = get_topk_cub(net, test_projectloader, 10, 'test_'+str(epoch), device, args)\n","      eval_prototypes_cub_parts_csv(csvfile_topk, parts_loc_path, parts_name_path, imgs_id_path, 'test_topk_'+str(epoch), args, log)\n","      cubthreshold = 0.5\n","      csvfile_all = get_proto_patches_cub(net, test_projectloader, 'test_'+str(epoch), device, args, threshold=cubthreshold)\n","      eval_prototypes_cub_parts_csv(csvfile_all, parts_loc_path, parts_name_path, imgs_id_path, 'test_all_thres'+str(cubthreshold)+'_'+str(epoch), args, log)\n","\n","    # visualize predictions\n","    visualize(net, projectloader, len(classes), device, 'visualised_prototypes', args)\n","    testset_img0_path = test_projectloader.dataset.samples[0][0]\n","    test_path = os.path.split(os.path.split(testset_img0_path)[0])[0]\n","    print(test_path)\n","    vis_pred(net, test_path, classes, device, args)\n","    if args.extra_test_image_folder != '':\n","        if os.path.exists(args.extra_test_image_folder):\n","            vis_pred_experiments(net, args.extra_test_image_folder, classes, device, args)\n","\n","\n","    best_model_path = os.path.join(args.log_dir, 'checkpoints', 'best_model.pth')\n","    last_model_path = os.path.join(args.log_dir, 'checkpoints', 'net_trained_last')\n","\n","# Check if the best model exists, otherwise use the last trained model\n","#Den kan räkna ut resultat\n","#Den kan räkna ut prototyper\n","#Det vi inte får och behöver mest är vad den använde för att förutse de olika klasserna\n","#Det är vad\n","    #best_model_path = \"/content/drive/MyDrive/PIPNet/runs/run_blood_80_prototypes/checkpoints/best_model.pth\"\n","    last_model_path = os.path.join(args.log_dir, 'checkpoints', 'net_trained_last')\n","\n","    # Check if the best model exists, otherwise use the last trained model\n","    if os.path.exists(best_model_path):\n","        model_path = best_model_path\n","        print(\"Using best model for evaluation and visualization.\")\n","    else:\n","        model_path = last_model_path\n","        print(\"Best model not found. Using last trained model for evaluation and visualization.\")\n","\n","    if os.path.exists(model_path):\n","        print(\"Loading best model for final evaluation and visualization...\", flush=True)\n","        checkpoint = torch.load(model_path, map_location=device)\n","        net.load_state_dict(checkpoint['model_state_dict'])\n","\n","        # Evaluate the best model\n","        eval_info = eval_pipnet(net, testloader2, 'best', device)\n","        print(\"Final evaluation metrics for the best model:\")\n","        for key, value in eval_info.items():\n","            print(f\"{key}: {value}\")\n","\n","        # Visualize predictions for the best model\n","        # Define a new directory for visualization\n","        # Ensure the directory exists and print paths for debugging\n","        new_visualization_dir = './visualizations_best_model'\n","        os.makedirs(new_visualization_dir, exist_ok=True)\n","        print(f\"Before updating, args.dir_for_saving_images={args.dir_for_saving_images}\")\n","        args.dir_for_saving_images = new_visualization_dir\n","        print(f\"After updating, args.dir_for_saving_images={args.dir_for_saving_images}\")\n","\n","        # Visualize prototypes\n","        visualize(net, projectloader, len(classes), device, 'visualised_prototypes_best_model', args)\n","\n","        # Get the test set image path\n","        testset_img0_path = test_projectloader2.dataset.samples[0][0]\n","        test_path = os.path.split(os.path.split(testset_img0_path)[0])[0]\n","        print(f\"Test path: {test_path}\")\n","\n","        # Visualize predictions\n","        vis_pred(net, test_path, classes, device, args)\n","\n","        # Check for extra test image folder\n","        if args.extra_test_image_folder != '':\n","            if os.path.exists(args.extra_test_image_folder):\n","                vis_pred_experiments(net, args.extra_test_image_folder, classes, device, args)\n","\n","\n","    print(\"Done!\", flush=True)\n"]},{"cell_type":"code","execution_count":null,"id":"OS2_-_yKIpqK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1720131093734,"user":{"displayName":"hanad abdullahi","userId":"11074746584642627268"},"user_tz":-120},"id":"OS2_-_yKIpqK","outputId":"49d0e311-733c-4052-cef1-73f1c1229feb"},"outputs":[{"name":"stdout","output_type":"stream","text":[" converter_notebook.py\t\t\t  nauta_pipnet_cpvr.png      run_test_code.py\n"," data_2.py\t\t\t\t  organized_pneumoniamnist   saved_images\n"," features\t\t\t\t  pipnet\t\t     used_arguments\n"," machinelearning_in_regulatory_genomics   pipnet_cub_trained\t     util\n"," main.ipynb\t\t\t\t  pretrained_models\t     visualizations_best_model\n","'main (kopia 2).py'\t\t\t  __pycache__\t\t     visualize_test.py\n","'main (kopia).py'\t\t\t  README.md\n"," main.py\t\t\t\t  runs\n"]}],"source":["!ls"]},{"cell_type":"code","execution_count":null,"id":"NpfyuT9o36RK","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"NpfyuT9o36RK","outputId":"f1406433-50d3-48c0-8b66-596d2fa5d896"},"outputs":[{"name":"stdout","output_type":"stream","text":["hej\n","Namespace(dataset='mri_scans', validation_size=0.2, net='resnet50', batch_size=64, batch_size_pretrain=128, epochs=70, epochs_pretrain=10, optimizer='Adam', lr=0.05, lr_block=0.0005, lr_net=0.0005, weight_decay=0.01, disable_cuda=False, log_dir='./runs/run_pipnet100', num_features=80, image_size=224, state_dict_dir_net='', freeze_epochs=2, dir_for_saving_images='./output_images', disable_pretrained=False, weighted_loss=False, seed=42, gpu_ids='0', num_workers=4, bias=True, extra_test_image_folder='./experiments')\n","hej\n","hej\n","hej\n"]}],"source":["\n","\n","if __name__ == '__main__':\n","    print(\"hej\")\n","    args = get_args()\n","\n","    torch.manual_seed(args.seed)\n","    print(args)\n","    torch.cuda.manual_seed_all(args.seed)\n","    random.seed(args.seed)\n","    print(\"hej\")\n","    np.random.seed(args.seed)\n","    print(\"hej\")\n","\n","    print_dir = os.path.join(args.log_dir, 'out.txt')\n","    tqdm_dir = os.path.join(args.log_dir, 'tqdm.txt')\n","    print(\"hej\")\n","    if not os.path.isdir(args.log_dir):\n","        os.mkdir(args.log_dir)\n","\n","    # Redirect stdout and stderr to the log files\n","    sys.stdout = open(print_dir, 'w')\n","    sys.stderr = open(tqdm_dir, 'w')\n","\n","    print(\"Redirected stdout and stderr\")\n","\n","    run_pipnet(args)\n","    print(\"what\")\n","\n","    # Ensure all buffers are flushed and files are closed\n","    sys.stdout.close()\n","    sys.stderr.close()\n","    \"\"\"\n","    hej\n","Namespace(dataset='mri_scans', validation_size=0.2, net='resnet50', batch_size=64, batch_size_pretrain=128, epochs=100, epochs_pretrain=10, optimizer='Adam', lr=0.05, lr_block=0.0005, lr_net=0.0005, weight_decay=0.01, disable_cuda=False, log_dir='./runs/run_pipnet18', num_features=80, image_size=224, state_dict_dir_net='', freeze_epochs=2, dir_for_saving_images='./output_images', disable_pretrained=False, weighted_loss=True, seed=42, gpu_ids='0', num_workers=4, bias=True, extra_test_image_folder='./experiments')\n","hej\n","hej\n","hej\n","\n","---------------------------------------------------------------------------\n","\n","ValueError                                Traceback (most recent call last)\n","\n","<ipython-input-8-040b019ceac7> in <cell line: 1>()\n","     23     print(\"Redirected stdout and stderr\")\n","     24\n","---> 25     run_pipnet(args)\n","     26     print(\"what\")\n","     27\n","\n","1 frames\n","\n","<ipython-input-6-0732d5072500> in run_pipnet(args)\n","    320     test_path = os.path.split(os.path.split(testset_img0_path)[0])[0]\n","    321     print(test_path)\n","--> 322     vis_pred(net, test_path, classes, device, args)\n","    323     if args.extra_test_image_folder != '':\n","    324         if os.path.exists(args.extra_test_image_folder):\n","\n","/content/drive/My Drive/PIPNet/util/visualize_prediction.py in vis_pred(net, vis_test_dir, classes, device, args)\n","    105\n","    106                             # Ensure the dimensions match\n","--> 107                             heatmap_img = 0.2 * np.float32(heatmap) + 0.6 * np.float32(img_np)\n","    108\n","    109                             plt.imsave(fname=os.path.join(save_path, 'heatmap_p%s.png' % str(prototype_idx.item())), arr=heatmap_img, vmin=0.0, vmax=1.0)\n","\n","ValueError: operands could not be broadcast together with shapes (224,224,3) (4,224,224)\n","\n","/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n","  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr()\n","    \"\"\"\n"]},{"cell_type":"code","execution_count":null,"id":"8b-V8lh3vHw6","metadata":{"id":"8b-V8lh3vHw6"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Load the CSV file\n","csv_file_path = '/content/drive/MyDrive/PIPNet/runs/run_pipnet28/log_epoch_overview.csv'  # Update with your CSV file path\n","df = pd.read_csv(csv_file_path)\n","\n","# Remove rows where 'test_top1_acc' or 'test_f1' are 'n.a.'\n","df = df[(df['test_top1_acc'] != 'n.a.')]\n","\n","# Filter out rows where 'epoch' contains non-numeric values\n","df = df[pd.to_numeric(df['epoch'], errors='coerce').notnull()]\n","\n","# Convert columns to numeric\n","df['epoch'] = pd.to_numeric(df['epoch'])\n","df['test_top1_acc'] = pd.to_numeric(df['test_top1_acc'])\n","\n","\n","# Plotting\n","plt.figure(figsize=(10, 6))\n","plt.plot(df['epoch'], df['test_top1_acc'], label='Test Accuracy', marker='o')\n","\n","# Adding labels and title\n","plt.xlabel('Epoch')\n","plt.ylabel('Metrics')\n","plt.title('validation Accuracy and F1 Score over Epochs')\n","plt.legend()\n","plt.grid(True)\n","\n","# Show the plot\n","plt.show()\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[]},"jupytext":{"cell_metadata_filter":"-all","main_language":"python","notebook_metadata_filter":"-all"},"kernelspec":{"display_name":"Python 3.10.14 ('deformable_protopnet')","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.14"},"vscode":{"interpreter":{"hash":"fd592a35cfe9e29df3fef78559ab94e5107d23b34b18b77c96678777bbb8d09d"}}},"nbformat":4,"nbformat_minor":5}
